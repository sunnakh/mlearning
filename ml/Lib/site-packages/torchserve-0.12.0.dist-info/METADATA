Metadata-Version: 2.1
Name: torchserve
Version: 0.12.0
Summary: TorchServe is a tool for serving neural net models for inference
Home-page: https://github.com/pytorch/serve.git
Author: PyTorch Serving team
Author-email: noreply@noreply.com
License: Apache License Version 2.0
Keywords: TorchServe PyTorch Serving Deep Learning Inference AI
Description-Content-Type: text/x-rst
License-File: LICENSE
Requires-Dist: Pillow
Requires-Dist: psutil
Requires-Dist: packaging
Requires-Dist: wheel
Provides-Extra: ipex
Requires-Dist: intel-extension-for-pytorch ; extra == 'ipex'
Provides-Extra: onnx
Requires-Dist: numpy ; extra == 'onnx'
Requires-Dist: onnx ; extra == 'onnx'
Requires-Dist: onnx-runtime ; extra == 'onnx'

Project Description
===================

TorchServe is a flexible and easy to use tool for
serving `PyTorch <http://pytorch.org/>`__ models in production.

Use the TorchServe CLI, or the pre-configured Docker images, to start a
service that sets up HTTP endpoints to handle model inference requests.

Installation
------------

Full installation instructions are in the project repo: https://github.com/pytorch/serve/blob/master/README.md


Source code
-----------

You can check the latest source code as follows:

::

    git clone https://github.com/pytorch/serve.git

Citation
--------

If you use torchserve in a publication or project, please cite torchserve:
https://github.com/pytorch/serve
