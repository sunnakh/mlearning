# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow_serving/apis/model_management.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import builder as _builder
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from tensorflow_serving.apis import status_pb2 as tensorflow__serving_dot_apis_dot_status__pb2
from tensorflow_serving.config import model_server_config_pb2 as tensorflow__serving_dot_config_dot_model__server__config__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n.tensorflow_serving/apis/model_management.proto\x12\x12tensorflow.serving\x1a$tensorflow_serving/apis/status.proto\x1a\x33tensorflow_serving/config/model_server_config.proto\"b\n\x13ReloadConfigRequest\x12\x35\n\x06\x63onfig\x18\x01 \x01(\x0b\x32%.tensorflow.serving.ModelServerConfig\x12\x14\n\x0cmetric_names\x18\x02 \x03(\t\"s\n\x14ReloadConfigResponse\x12/\n\x06status\x18\x01 \x01(\x0b\x32\x1f.tensorflow.serving.StatusProto\x12*\n\x06metric\x18\x02 \x03(\x0b\x32\x1a.tensorflow.serving.Metric\"H\n\x06Metric\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1e\n\x14int64_value_increase\x18\x02 \x01(\x03H\x00\x42\x10\n\x0evalue_increaseB\x03\xf8\x01\x01\x62\x06proto3')

_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals())
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tensorflow_serving.apis.model_management_pb2', globals())
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\370\001\001'
  _RELOADCONFIGREQUEST._serialized_start=161
  _RELOADCONFIGREQUEST._serialized_end=259
  _RELOADCONFIGRESPONSE._serialized_start=261
  _RELOADCONFIGRESPONSE._serialized_end=376
  _METRIC._serialized_start=378
  _METRIC._serialized_end=450
# @@protoc_insertion_point(module_scope)
